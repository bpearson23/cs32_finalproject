{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9469ca89-3430-4226-b1bc-e9d9405d6d3a",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "15976d43-13fd-45d9-925b-4ba76cb08b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259db3af-580b-43a2-84aa-5a6c91a5ea5a",
   "metadata": {},
   "source": [
    "# Load in Existing Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e4030e18-86f6-4220-9892-56d9b8248c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = pd.read_csv(\"scraped_data.csv\")\n",
    "scraped_data.set_index(list(scraped_data.columns)[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46863066-1b55-4e53-b33e-e55ef328c591",
   "metadata": {},
   "source": [
    "# OG Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "34b731de-c304-45a7-8810-38948aff9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_dict = {}\n",
    "categories = ['Distillery', 'Age', 'Vintage', 'Region', 'Bottler', 'Cask Type', 'Bottled Strength', 'Bottle Size',\n",
    "             'Distillery Status']\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "}\n",
    "date_format = \"%m.%d.%y\"\n",
    "per_page = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5cda5889-09cc-4ce8-b51d-0031321f4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def og_scraper():\n",
    "    '''Scrapes data from Whiskey Auctioneer and saves to dictionary'''\n",
    "    \n",
    "    # more_new_data = True\n",
    "\n",
    "    # URL of the first page of results\n",
    "    url_stem = \"https://whiskyauctioneer.com/auction-search\"\n",
    "    \n",
    "    url = True\n",
    "    \n",
    "    live_url = \"https://whiskyauctioneer.com/current-auction\"\n",
    "    page = requests.get(live_url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    start_page = math.floor(int(re.findall(r'\\d+', soup.find(\"p\", class_ = \"left\").text)[0]) / per_page)-1\n",
    "    \n",
    "    i = start_page\n",
    "    #i = 209\n",
    "    \n",
    "    # Loop through remaining pages until you get to where there aren't any more\n",
    "    while url:\n",
    "        print(i)\n",
    "        \n",
    "        if i == 0:\n",
    "            url = url_stem\n",
    "        else:\n",
    "            url = url_stem + f'?page={i}'\n",
    "\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        \n",
    "        result_1 = soup.find(\"div\", class_ =\"views-row views-row-1 views-row-odd views-row-first producthomepage\")\n",
    "        result = result_1\n",
    "        # Now we need to iterate through the lots on the page\n",
    "        while result:\n",
    "            lot_dict = {}\n",
    "            \n",
    "            lot_num = int(re.findall(r'\\d+', result.find(\"span\", class_ = \"lotnumber label-lot\").text)[0])\n",
    "            if lot_num in list(scraped_data.index):\n",
    "                more_new_data = False\n",
    "                continue\n",
    "            \n",
    "            # Skip this iteration if the lot is part of a current auction:\n",
    "            if \"Bid Now\" in result.text:\n",
    "                result = result.nextSibling\n",
    "                continue\n",
    "                 \n",
    "            lot_dict[\"name\"] = result.find(\"a\")[\"_title\"]\n",
    "            lot_dict[\"price\"] = int(''.join(re.findall(r'\\d+', result.find(\"div\", class_ = \"lotwin cru\").text)))\n",
    "            lot_dict['reserve_met'] = 1 if \"Reserve not met\" in result.find(\"div\", class_ = \"lotwin cru\").text else 0\n",
    "            lot_dict['end_date'] = datetime.strptime(result.find(\"div\", \n",
    "                                class_ = \"enddatein\").text.split(':')[1].strip(), date_format).date()\n",
    "            lot_num = int(re.findall(r'\\d+', result.find(\"span\", class_ = \"lotnumber label-lot\").text)[0])\n",
    "               \n",
    "            # Get lot site\n",
    "            lot_url = result.find(\"a\", href=True)['href']\n",
    "            \n",
    "            lot_page = requests.get(lot_url, headers=headers)\n",
    "            lot_soup = BeautifulSoup(lot_page.content, \"html.parser\")\n",
    "            \n",
    "            child = lot_soup.find(\"div\", class_ = \"whiskyproduct\").findChild()\n",
    "            # Iterate through children to get all info\n",
    "            while child:\n",
    "                \n",
    "                for val in categories:\n",
    "                    if val in child.text:\n",
    "                        cat = val\n",
    "                        \n",
    "                value = str(child.text).replace(\"\\xa0\", '').split(':')[1]\n",
    "                \n",
    "                lot_dict[cat] = value\n",
    "                \n",
    "                child = child.nextSibling\n",
    "                \n",
    "            prod_details = lot_soup.find(\"div\", {\"class\": \"field-item even\", \n",
    "                                                 \"property\": \"content:encoded\"}).text.replace(\"\\xa0\", '')\n",
    "            \n",
    "            lot_dict['details'] = prod_details\n",
    "                \n",
    "            lots_dict[lot_num] = lot_dict\n",
    "            \n",
    "            # This iterates the loop to the next lot\n",
    "            result = result.nextSibling\n",
    "        \n",
    "        i += 1\n",
    "        time.sleep(3)\n",
    "         \n",
    "        \n",
    "    return lots_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c3466074-2249-49e1-ae41-44b09e99b125",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "207\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-291-862d1514ef7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mog_scraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-288-cd8ebb73ec06>\u001b[0m in \u001b[0;36mog_scraper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mlot_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mlot_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"span\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lotnumber label-lot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlot_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscraped_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mmore_new_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, name, attrs, recursive, text, **kwargs)\u001b[0m\n\u001b[1;32m   1759\u001b[0m         \"\"\"\n\u001b[1;32m   1760\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36mfind_all\u001b[0;34m(self, name, attrs, recursive, text, limit, **kwargs)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1788\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1789\u001b[0m     \u001b[0mfindAll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all\u001b[0m       \u001b[0;31m# BS3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m     \u001b[0mfindChildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_all\u001b[0m  \u001b[0;31m# BS2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_find_all\u001b[0;34m(self, name, attrs, text, limit, generator, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2066\u001b[0m         \u001b[0;31m# If it's text, make sure the text matches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNavigableString\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36msearch_tag\u001b[0;34m(self, markup_name, markup_attrs)\u001b[0m\n\u001b[1;32m   2026\u001b[0m                                 \u001b[0mmarkup_attr_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2027\u001b[0m                     \u001b[0mattr_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkup_attr_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2028\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_against\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2029\u001b[0m                         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_matches\u001b[0;34m(self, markup, match_against, already_tried)\u001b[0m\n\u001b[1;32m   2081\u001b[0m             \u001b[0;31m# like 'class'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_against\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m             \u001b[0;31m# We didn't match any particular value of the multivalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m_matches\u001b[0;34m(self, markup, match_against, already_tried)\u001b[0m\n\u001b[1;32m   2110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch_against\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m         if (hasattr(match_against, '__iter__')\n\u001b[0m\u001b[1;32m   2113\u001b[0m             and not isinstance(match_against, str)):\n\u001b[1;32m   2114\u001b[0m             \u001b[0;31m# We're asked to match against an iterable of items.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "og_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc860e-dd1d-4475-a064-2ab85cba795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = pd.DataFrame.from_dict(lots_dict, orient = \"index\")\n",
    "scraped_data.to_csv(\"scraped_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d35a4-8932-4a86-bae2-9f876de363d6",
   "metadata": {},
   "source": [
    "# Iterative Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "e375a205-e1cb-49c1-9977-a016baa0027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper():\n",
    "    '''Scrapes data from Whiskey Auctioneer and saves to dictionary'''\n",
    "    \n",
    "    more_new_data = True\n",
    "\n",
    "    # URL of the first page of results\n",
    "    url_stem = \"https://whiskyauctioneer.com/auction-search\"\n",
    "    \n",
    "    url = True\n",
    "    \n",
    "    live_url = \"https://whiskyauctioneer.com/current-auction\"\n",
    "    page = requests.get(live_url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    start_page = math.floor(int(re.findall(r'\\d+', soup.find(\"p\", class_ = \"left\").text)[0]) / per_page)-1\n",
    "    \n",
    "    i = start_page\n",
    "    #i = 209\n",
    "    \n",
    "    # Loop through remaining pages until you get to where there aren't any more\n",
    "    while url and more_new_data:\n",
    "        print(i)\n",
    "        \n",
    "        if i == 0:\n",
    "            url = url_stem\n",
    "        else:\n",
    "            url = url_stem + f'?page={i}'\n",
    "\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        \n",
    "        result_1 = soup.find(\"div\", class_ =\"views-row views-row-1 views-row-odd views-row-first producthomepage\")\n",
    "        result = result_1\n",
    "        # Now we need to iterate through the lots on the page\n",
    "        while result and more_new_data:\n",
    "            lot_dict = {}\n",
    "            \n",
    "            lot_num = int(re.findall(r'\\d+', result.find(\"span\", class_ = \"lotnumber label-lot\").text)[0])\n",
    "            if lot_num in list(scraped_data.index):\n",
    "                more_new_data = False\n",
    "            \n",
    "            # Skip this iteration if the lot is part of a current auction:\n",
    "            if \"Bid Now\" in result.text:\n",
    "                result = result.nextSibling\n",
    "                continue\n",
    "                 \n",
    "            lot_dict[\"name\"] = result.find(\"a\")[\"_title\"]\n",
    "            lot_dict[\"price\"] = int(''.join(re.findall(r'\\d+', result.find(\"div\", class_ = \"lotwin cru\").text)))\n",
    "            lot_dict['reserve_met'] = 1 if \"Reserve not met\" in result.find(\"div\", class_ = \"lotwin cru\").text else 0\n",
    "            lot_dict['end_date'] = datetime.strptime(result.find(\"div\", \n",
    "                                class_ = \"enddatein\").text.split(':')[1].strip(), date_format).date()\n",
    "            lot_num = int(re.findall(r'\\d+', result.find(\"span\", class_ = \"lotnumber label-lot\").text)[0])\n",
    "               \n",
    "            # Get lot site\n",
    "            lot_url = result.find(\"a\", href=True)['href']\n",
    "            \n",
    "            lot_page = requests.get(lot_url, headers=headers)\n",
    "            lot_soup = BeautifulSoup(lot_page.content, \"html.parser\")\n",
    "            \n",
    "            child = lot_soup.find(\"div\", class_ = \"whiskyproduct\").findChild()\n",
    "            # Iterate through children to get all info\n",
    "            while child:\n",
    "                \n",
    "                for val in categories:\n",
    "                    if val in child.text:\n",
    "                        cat = val\n",
    "                        \n",
    "                value = str(child.text).replace(\"\\xa0\", '').split(':')[1]\n",
    "                \n",
    "                lot_dict[cat] = value\n",
    "                \n",
    "                child = child.nextSibling\n",
    "                \n",
    "            prod_details = lot_soup.find(\"div\", {\"class\": \"field-item even\", \n",
    "                                                 \"property\": \"content:encoded\"}).text.replace(\"\\xa0\", '')\n",
    "            \n",
    "            lot_dict['details'] = prod_details\n",
    "                \n",
    "            lots_dict[lot_num] = lot_dict\n",
    "            \n",
    "            # This iterates the loop to the next lot\n",
    "            result = result.nextSibling\n",
    "        \n",
    "        i += 1\n",
    "        time.sleep(3)\n",
    "         \n",
    "        \n",
    "    return lots_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2ea7affe-cb80-4d38-9305-8314331ed36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "98f0b541-c25c-4465-85db-e6b561e2742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = pd.DataFrame.from_dict(lots_dict, orient = \"index\")\n",
    "scraped_data.to_csv(\"scraped_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ca2a8-0287-4ceb-87c1-0481ec2ac6cf",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522b889-c4e2-4214-9e35-edc3ccd642be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression = distillery (ex = Wild Turkey), age, proof, vintage (year), \n",
    "# uniquely identify each expression and track price over time\n",
    "# only care about "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
