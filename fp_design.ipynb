{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9469ca89-3430-4226-b1bc-e9d9405d6d3a",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15976d43-13fd-45d9-925b-4ba76cb08b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259db3af-580b-43a2-84aa-5a6c91a5ea5a",
   "metadata": {},
   "source": [
    "# Load in Existing Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4030e18-86f6-4220-9892-56d9b8248c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = pd.read_csv(\"scraped_data.csv\")\n",
    "scraped_data.set_index(list(scraped_data.columns)[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46863066-1b55-4e53-b33e-e55ef328c591",
   "metadata": {},
   "source": [
    "# OG Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b731de-c304-45a7-8810-38948aff9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_dict = {}\n",
    "categories = ['Distillery', 'Age', 'Vintage', 'Region', 'Bottler', 'Cask Type', 'Bottled Strength', 'Bottle Size',\n",
    "             'Distillery Status']\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "}\n",
    "date_format = \"%m.%d.%y\"\n",
    "per_page = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cda5889-09cc-4ce8-b51d-0031321f4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def og_scraper():\n",
    "    '''Scrapes data from Whiskey Auctioneer and saves to dictionary'''\n",
    "    \n",
    "    # more_new_data = True\n",
    "\n",
    "    # URL of the first page of results\n",
    "    url_stem = \"https://whiskyauctioneer.com/auction-search\"\n",
    "    \n",
    "    url = True\n",
    "    \n",
    "    live_url = \"https://whiskyauctioneer.com/current-auction\"\n",
    "    page = requests.get(live_url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    start_page = math.floor(int(re.findall(r'\\d+', soup.find(\"p\", class_ = \"left\").text)[0]) / per_page)-1\n",
    "    \n",
    "    i = start_page\n",
    "    #i = 207\n",
    "    \n",
    "    # Loop through remaining pages until you get to where there aren't any more\n",
    "    while url:\n",
    "        \n",
    "        if i == 0:\n",
    "            url = url_stem\n",
    "        else:\n",
    "            url = url_stem + f'?page={i}'\n",
    "\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        \n",
    "        result_1 = soup.find(\"div\", class_ =\"views-row views-row-1 views-row-odd views-row-first producthomepage\")\n",
    "        result = result_1\n",
    "        \n",
    "        # Now we need to iterate through the lots on the page\n",
    "        counter = 0\n",
    "        while result != '':\n",
    "            print(counter)\n",
    "            counter+= 1\n",
    "\n",
    "            lot_dict = {}\n",
    "            \n",
    "            lot_num = int(re.findall(r'\\d+', result.find(\"span\", class_ = \"lotnumber label-lot\").text)[0])\n",
    "            if lot_num in list(scraped_data.index):\n",
    "                more_new_data = False\n",
    "                continue\n",
    "            \n",
    "            # Skip this iteration if the lot is part of a current auction:\n",
    "            if \"Bid Now\" in result.text:\n",
    "                result = result.nextSibling\n",
    "                continue\n",
    "                 \n",
    "            lot_dict[\"name\"] = result.find(\"a\")[\"_title\"]\n",
    "            lot_dict[\"price\"] = int(''.join(re.findall(r'\\d+', result.find(\"div\", class_ = \"lotwin cru\").text)))\n",
    "            lot_dict['reserve_met'] = 1 if \"Reserve not met\" in result.find(\"div\", class_ = \"lotwin cru\").text else 0\n",
    "            lot_dict['end_date'] = datetime.strptime(result.find(\"div\", \n",
    "                                class_ = \"enddatein\").text.split(':')[1].strip(), date_format).date()\n",
    "            lot_num = int(re.findall(r'\\d+', result.find(\"span\", class_ = \"lotnumber label-lot\").text)[0])\n",
    "               \n",
    "            # Get lot site\n",
    "            lot_url = result.find(\"a\", href=True)['href']\n",
    "            \n",
    "            lot_page = requests.get(lot_url, headers=headers)\n",
    "            lot_soup = BeautifulSoup(lot_page.content, \"html.parser\")\n",
    "            \n",
    "            child = lot_soup.find(\"div\", class_ = \"whiskyproduct\").findChild()\n",
    "            # Iterate through children to get all info\n",
    "            while child:\n",
    "                \n",
    "                for val in categories:\n",
    "                    if val in child.text:\n",
    "                        cat = val\n",
    "                        \n",
    "                value = str(child.text).replace(\"\\xa0\", '').split(':')[1]\n",
    "                \n",
    "                lot_dict[cat] = value\n",
    "                \n",
    "                child = child.nextSibling\n",
    "                \n",
    "            prod_details = lot_soup.find(\"div\", {\"class\": \"field-item even\", \n",
    "                                                 \"property\": \"content:encoded\"}).text.replace(\"\\xa0\", '')\n",
    "            \n",
    "            lot_dict['details'] = prod_details\n",
    "                \n",
    "            lots_dict[lot_num] = lot_dict\n",
    "            \n",
    "            # This iterates the loop to the next lot\n",
    "            result = result.nextSibling\n",
    "        \n",
    "        print(f\"Done page {i}\")\n",
    "        i += 1\n",
    "        time.sleep(3)\n",
    "         \n",
    "        \n",
    "    return lots_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3466074-2249-49e1-ae41-44b09e99b125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-862d1514ef7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mog_scraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-a1faf7b6f13c>\u001b[0m in \u001b[0;36mog_scraper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlive_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mstart_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mper_page\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "og_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6603c10b-2f90-4465-833c-3c87a45958ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-86276cfd7e84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlive_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstart_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mper_page\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "live_url = \"https://whiskyauctioneer.com/current-auction\"\n",
    "page = requests.get(live_url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "start_page = math.floor(int(re.findall(r'\\d+', soup.find(\"p\", class_ = \"left\").text)[0]) / per_page)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752011aa-dfb7-49b6-a563-c4c8568bc2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc860e-dd1d-4475-a064-2ab85cba795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = pd.DataFrame.from_dict(lots_dict, orient = \"index\")\n",
    "scraped_data.to_csv(\"scraped_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d35a4-8932-4a86-bae2-9f876de363d6",
   "metadata": {},
   "source": [
    "# Iterative Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "e375a205-e1cb-49c1-9977-a016baa0027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper():\n",
    "    '''Scrapes data from Whiskey Auctioneer and saves to dictionary'''\n",
    "    \n",
    "    more_new_data = True\n",
    "\n",
    "    # URL of the first page of results\n",
    "    url_stem = \"https://whiskyauctioneer.com/auction-search\"\n",
    "    \n",
    "    url = True\n",
    "    \n",
    "    live_url = \"https://whiskyauctioneer.com/current-auction\"\n",
    "    page = requests.get(live_url, headers=headers)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    start_page = math.floor(int(re.findall(r'\\d+', soup.find(\"p\", class_ = \"left\").text)[0]) / per_page)-1\n",
    "    \n",
    "    i = start_page\n",
    "    #i = 209\n",
    "    \n",
    "    # Loop through remaining pages until you get to where there aren't any more\n",
    "    while url and more_new_data:\n",
    "        print(i)\n",
    "        \n",
    "        if i == 0:\n",
    "            url = url_stem\n",
    "        else:\n",
    "            url = url_stem + f'?page={i}'\n",
    "\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        \n",
    "        result_1 = soup.find(\"div\", class_ =\"views-row views-row-1 views-row-odd views-row-first producthomepage\")\n",
    "        result = result_1\n",
    "        # Now we need to iterate through the lots on the page\n",
    "        while result and more_new_data:\n",
    "            lot_dict = {}\n",
    "            \n",
    "            lot_num = int(re.findall(r'\\d+', result.find(\"span\", class_ = \"lotnumber label-lot\").text)[0])\n",
    "            if lot_num in list(scraped_data.index):\n",
    "                more_new_data = False\n",
    "            \n",
    "            # Skip this iteration if the lot is part of a current auction:\n",
    "            if \"Bid Now\" in result.text:\n",
    "                result = result.nextSibling\n",
    "                continue\n",
    "                 \n",
    "            lot_dict[\"name\"] = result.find(\"a\")[\"_title\"]\n",
    "            lot_dict[\"price\"] = int(''.join(re.findall(r'\\d+', result.find(\"div\", class_ = \"lotwin cru\").text)))\n",
    "            lot_dict['reserve_met'] = 1 if \"Reserve not met\" in result.find(\"div\", class_ = \"lotwin cru\").text else 0\n",
    "            lot_dict['end_date'] = datetime.strptime(result.find(\"div\", \n",
    "                                class_ = \"enddatein\").text.split(':')[1].strip(), date_format).date()\n",
    "            lot_num = int(re.findall(r'\\d+', result.find(\"span\", class_ = \"lotnumber label-lot\").text)[0])\n",
    "               \n",
    "            # Get lot site\n",
    "            lot_url = result.find(\"a\", href=True)['href']\n",
    "            \n",
    "            lot_page = requests.get(lot_url, headers=headers)\n",
    "            lot_soup = BeautifulSoup(lot_page.content, \"html.parser\")\n",
    "            \n",
    "            child = lot_soup.find(\"div\", class_ = \"whiskyproduct\").findChild()\n",
    "            # Iterate through children to get all info\n",
    "            while child:\n",
    "                \n",
    "                for val in categories:\n",
    "                    if val in child.text:\n",
    "                        cat = val\n",
    "                        \n",
    "                value = str(child.text).replace(\"\\xa0\", '').split(':')[1]\n",
    "                \n",
    "                lot_dict[cat] = value\n",
    "                \n",
    "                child = child.nextSibling\n",
    "                \n",
    "            prod_details = lot_soup.find(\"div\", {\"class\": \"field-item even\", \n",
    "                                                 \"property\": \"content:encoded\"}).text.replace(\"\\xa0\", '')\n",
    "            \n",
    "            lot_dict['details'] = prod_details\n",
    "                \n",
    "            lots_dict[lot_num] = lot_dict\n",
    "            \n",
    "            # This iterates the loop to the next lot\n",
    "            result = result.nextSibling\n",
    "        \n",
    "        i += 1\n",
    "        time.sleep(3)\n",
    "         \n",
    "        \n",
    "    return lots_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2ea7affe-cb80-4d38-9305-8314331ed36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "98f0b541-c25c-4465-85db-e6b561e2742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data = pd.DataFrame.from_dict(lots_dict, orient = \"index\")\n",
    "scraped_data.to_csv(\"scraped_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ca2a8-0287-4ceb-87c1-0481ec2ac6cf",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522b889-c4e2-4214-9e35-edc3ccd642be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression = distillery (ex = Wild Turkey), age, proof, vintage (year), \n",
    "# uniquely identify each expression and track price over time\n",
    "# only care about "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
